<h2 class="section-title">{{ .titles.overview }}</h2>

<p class="about-list-header">Planning and learning are two fundamental capabilities of robots. While planning seeks to solve a task by synthesizing policies on the fly, learning seeks to obtain solutions from experiences provided by data. The two domains have independently advanced in the past decades and both achieved remarkable success on their most suitable tasks. There is a noticeable trend to combine these two capabilities. Particularly, there are the following complementary directions:</p>
<ul class="about-list">
  <li class="about-item"><i>Learning to plan</i>: Learning heuristics, sampling distributions, action abstractions, etc. for planning.</li>
  <li class="about-item"><i>Planning to learn</i>: Learning from planners; active learning; uncertainty-aware learning, etc.</li>
  <li class="about-item"><i>Differentiable planners</i>: Embedding the structure of planners into neural networks to learn both the model and planner parameters end-to-end.</li>
  <li class="about-item"><i>Model learning</i>: Learning dynamics and observation models for complex domains and use them for planning.</li>
  <li class="about-item"><i>Learning representations</i>: Learning state, observation or belief representations to enable efficient planning with high-dimensional observation spaces.</li>
  <li class="about-item"><i>Model augmented RL</i>: Leveraging models to augment learning and achieve sample-efficiency.</li>
</ul>
<br/>
<p class="about-list-header">However, what is missing is a systematic discussion on where and how these strategies shall be best applied and how they can be seamlessly combined. For example:</p>
<ul class="about-list">
  <li class="about-item">How can we quantify that a learned model is useful beyond its prediction accuracy, i.e. it enables efficient planning and reasoning?</li>
  <li class="about-item">How are the principles of planning to learn and learning to plan different from standard planning and learning principles?</li>
  <li class="about-item">How to use learning subcomponents “properly” in planning, desirablly with theoretical guarantees?</li>
  <li class="about-item">What meta-problems in learning can be formulated as planning problem?</li>
  <li class="about-item">Are differentiable planners merely structural priors for deep RL, or beyond that?</li>
</ul>

<br/>
<p class="about-description">In this workshop, we aim to bring together researchers in the planning and learning sub-domains, to discuss new opportunities to integrate them and to incubate the next level of intelligence.</p>

<br/>
<p class="about-description">We invite you to provide questions for our panels <b><u><a href="https://docs.google.com/forms/d/e/1FAIpQLSd-LF12Sk-M6u5OqJ1H2O8K1uSDg8wAvXS3y9eZiMbKMHIemw/viewform?usp=sf_link">here</a></u>.</b></p>

<br/>
<p class="about-description">To attend the workshop virtually, please use the <b><u><a href="https://pheedloop.com/rss2021/virtual/?page=sessions&section=SESCWJ95K3X0Q85WD" target="#">RSS PheedLoop Conference System</a></u></b>.
